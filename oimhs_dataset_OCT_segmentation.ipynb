{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME88KCYtHSydZK0jQ7x7/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hariomshahu/oimhs_dataset_segmentation/blob/main/oimhs_dataset_OCT_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download and Unzip Data"
      ],
      "metadata": {
        "id": "3oXuB1aMiuET"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6QhfuDQUX91",
        "outputId": "7b51525b-6b4a-4d81-da08-52b944464162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-07 13:19:13--  https://springernature.figshare.com/ndownloader/files/42522673\n",
            "Resolving springernature.figshare.com (springernature.figshare.com)... 52.17.248.128, 54.229.18.180, 2a05:d018:1f4:d000:7459:343e:6685:308f, ...\n",
            "Connecting to springernature.figshare.com (springernature.figshare.com)|52.17.248.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3-eu-west-1.amazonaws.com/pstorage-npg-968563215/42522673/OIMHSdataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIQYK5H3JTELHKKTA/20240707/eu-west-1/s3/aws4_request&X-Amz-Date=20240707T131914Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=f5c41903e23ebf2c243e8713586d48517661ab07a8c812c7ba22f0528917f57d [following]\n",
            "--2024-07-07 13:19:14--  https://s3-eu-west-1.amazonaws.com/pstorage-npg-968563215/42522673/OIMHSdataset.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIQYK5H3JTELHKKTA/20240707/eu-west-1/s3/aws4_request&X-Amz-Date=20240707T131914Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=f5c41903e23ebf2c243e8713586d48517661ab07a8c812c7ba22f0528917f57d\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.92.2.0, 52.92.19.24, 52.218.30.139, ...\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.92.2.0|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 979452748 (934M) [application/zip]\n",
            "Saving to: ‘/content/oimhs_dataset/oimhs_dataset.zip’\n",
            "\n",
            "/content/oimhs_data 100%[===================>] 934.08M  32.2MB/s    in 31s     \n",
            "\n",
            "2024-07-07 13:19:46 (29.9 MB/s) - ‘/content/oimhs_dataset/oimhs_dataset.zip’ saved [979452748/979452748]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create a directory to store the dataset\n",
        "os.makedirs('/content/oimhs_dataset', exist_ok=True)\n",
        "\n",
        "# Download the dataset using wget\n",
        "!wget -O /content/oimhs_dataset/oimhs_dataset.zip \"https://springernature.figshare.com/ndownloader/files/42522673\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip the dataset\n",
        "with zipfile.ZipFile('/content/oimhs_dataset/oimhs_dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/oimhs_dataset')\n"
      ],
      "metadata": {
        "id": "h-46b7O_WjAg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create folders containing images and masks"
      ],
      "metadata": {
        "id": "r7uXpJMRgJgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Paths to main directories and files\n",
        "images_dir = os.path.join('/content/oimhs_dataset', 'Images')\n",
        "\n",
        "# Create output directories\n",
        "output_dir = '/content/output_directory_for_dataset'\n",
        "images_output_dir = os.path.join(output_dir, 'images')\n",
        "masks_output_dir = os.path.join(output_dir, 'masks')\n",
        "os.makedirs(images_output_dir, exist_ok=True)\n",
        "os.makedirs(masks_output_dir, exist_ok=True)\n",
        "\n",
        "# Initialize counters for unique numbering\n",
        "image_counter = 1\n",
        "\n",
        "# Iterate through image folders\n",
        "for eye_folder in sorted(os.listdir(images_dir)):\n",
        "    eye_folder_path = os.path.join(images_dir, eye_folder)\n",
        "    if os.path.isdir(eye_folder_path):\n",
        "        for image_file in sorted(os.listdir(eye_folder_path)):\n",
        "            if image_file.endswith('.png'):\n",
        "                image_path = os.path.join(eye_folder_path, image_file)\n",
        "                image_name, ext = os.path.splitext(image_file)\n",
        "\n",
        "                # Load the composite image\n",
        "                img_composite = Image.open(image_path)\n",
        "\n",
        "                # Split the composite image into original OCT and ground truth parts\n",
        "                width, height = img_composite.size\n",
        "                half_width = width // 2\n",
        "                img_original = img_composite.crop((0, 0, half_width, height))\n",
        "                img_ground_truth = img_composite.crop((half_width, 0, width, height))\n",
        "\n",
        "                # Resize images if necessary (adjust as needed)\n",
        "                img_original = img_original.resize((256, 256))\n",
        "                img_ground_truth = img_ground_truth.resize((256, 256))\n",
        "\n",
        "                # Save OCT image to images_output_dir with unique numbering\n",
        "                oct_image_filename = f\"{image_counter}_oct.png\"\n",
        "                oct_image_path = os.path.join(images_output_dir, oct_image_filename)\n",
        "                img_original.save(oct_image_path)\n",
        "\n",
        "                # Save ground truth image (mask) to masks_output_dir with unique numbering\n",
        "                mask_filename = f\"{image_counter}_mask.png\"\n",
        "                mask_image_path = os.path.join(masks_output_dir, mask_filename)\n",
        "                img_ground_truth.save(mask_image_path)\n",
        "\n",
        "                # Increment counter for the next image\n",
        "                image_counter += 1\n"
      ],
      "metadata": {
        "id": "L7EIALBggHCx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Model"
      ],
      "metadata": {
        "id": "QxlKDgUNi4x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(inputs, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    x = conv_block(inputs, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(inputs, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNET\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "KuoCdIx4i_uo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Dataset"
      ],
      "metadata": {
        "id": "4fPG-u9XjoZm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vlMamWp7j0HU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}